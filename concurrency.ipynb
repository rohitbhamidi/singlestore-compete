{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from pinecone import Pinecone\n",
    "import psycopg2\n",
    "import singlestoredb as s2\n",
    "\n",
    "import time\n",
    "import concurrent.futures\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The wikipedia data is located in an open S3 bucket: `s3://wikipedia-video-game-data/video-game-embeddings(1).csv` in `us-west-1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_conn_str = f'enter your mongo connection string here'\n",
    "client = MongoClient(mongo_conn_str, server_api=ServerApi('1'))\n",
    "\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "    db = client.your_db_name\n",
    "    collection = db.your_collection_name\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection parameters for postgres\n",
    "host = \"your postgres host\"\n",
    "dbname = \"your db name\"\n",
    "user = \"your username\"\n",
    "\n",
    "# Create the connection string without a password\n",
    "conn_string = f\"dbname='{dbname}' user='{user}' host='{host}'\"\n",
    "conn = psycopg2.connect(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_host='your singlestore host'\n",
    "port='3306'\n",
    "username='admin'\n",
    "password='your singlestore password'\n",
    "database='your singlestore database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key='your pinecone api key')\n",
    "index = pc.Index(\"your pinecone index name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setting the Search Execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = collection.find_one({\"_id\": \"2251799813701581\"})\n",
    "query_vector = query[\"vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_mongo_search(query_vector):\n",
    "    pipeline = [\n",
    "        {\n",
    "            '$vectorSearch': {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"path\": \"vector\",\n",
    "                \"queryVector\": query_vector,\n",
    "                \"numCandidates\": 200,\n",
    "                \"limit\": 200  # Limit the number of results as needed\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$addFields': {\n",
    "                'keyword_bonus': {\n",
    "                    '$cond': {\n",
    "                        'if': {'$regexMatch': {'input': \"$paragraph\", 'regex': \"AAA games\"}},\n",
    "                        'then': 1.0,\n",
    "                        'else': 0.0\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$addFields': {\n",
    "                'custom_score': {\n",
    "                    '$add': [\n",
    "                        {'$multiply': [{'$subtract': [1, 0.3]}, '$score']},  # Adjust weight as necessary\n",
    "                        {'$multiply': [0.3, '$keyword_bonus']}  # Adjust weight as necessary\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$project': {\n",
    "                '_id': 1,\n",
    "                'paragraph': 1,\n",
    "                'custom_score': 1\n",
    "            }\n",
    "        },\n",
    "        {'$sort': {'custom_score': -1}},  # Sort by custom score descending\n",
    "        {'$limit': 5}  # Limit the results if needed\n",
    "    ]\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return list(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MongoDB: Running the Concurrent Queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_concurrent_queries = 250\n",
    "start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent_queries) as executor:\n",
    "    futures = [executor.submit(execute_mongo_search, query_vector) for _ in range(num_concurrent_queries)]\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Executed {num_concurrent_queries} concurrent queries.\")\n",
    "print(f\"Total execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "failed_count = sum(1 for f in futures if f.exception() is not None)\n",
    "print(f\"Failed queries: {failed_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pinecone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_pinecone_search(id, keywords):\n",
    "    try:\n",
    "        vector_search = index.query(id=id, top_k=200, include_metadata=True)\n",
    "        filtered_results = []\n",
    "        \n",
    "        for result in vector_search[\"matches\"]:\n",
    "            document = collection.find_one({\"_id\": str(result[\"id\"])})\n",
    "            if document:\n",
    "                paragraph = document[\"paragraph\"]\n",
    "                pinecone_score = result[\"score\"]\n",
    "                keyword_bonus = 1.0 if keywords in paragraph else 0.0\n",
    "                custom_score = (1-0.3)*pinecone_score + 0.3*keyword_bonus\n",
    "                filtered_results.append((result[\"id\"], paragraph, custom_score))\n",
    "        return filtered_results\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Failed to process query\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pinecone: Running the Concurrent Queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_concurrent_queries = 250\n",
    "id_to_query = \"2251799813701581\"  # Placeholder for the ID to query\n",
    "keywords_to_search = \"AAA games\"  # Placeholder for the keywords to check in the paragraph\n",
    "start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent_queries) as executor:\n",
    "    futures = [executor.submit(execute_pinecone_search, id_to_query, keywords_to_search) for _ in range(num_concurrent_queries)]\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Checking failed futures\n",
    "failed_count = sum(1 for f in futures if f.exception() is not None)\n",
    "\n",
    "print(f\"Executed {num_concurrent_queries} concurrent queries in {end_time - start_time} seconds\")\n",
    "print(f\"Failed queries: {failed_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pgvector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_vector_pg(id):\n",
    "    with psycopg2.connect(dbname=dbname, user=user, host=host) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT embedding FROM video_game_wikipedia WHERE id = %s;\", (id,))\n",
    "            result = cursor.fetchone()\n",
    "            return result[0] if result else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_pgvector_search(query_vector):\n",
    "    if not query_vector:\n",
    "        return []\n",
    "\n",
    "    sql_query = '''\n",
    "    WITH vector_query AS (\n",
    "    SELECT id, paragraph,\n",
    "           (embedding <#> %s) AS vector_score \n",
    "    FROM video_game_wikipedia\n",
    "    ORDER BY vector_score\n",
    "    LIMIT 200\n",
    "    ),\n",
    "    fts_query AS (\n",
    "        SELECT id, paragraph,\n",
    "            ts_rank_cd(paragraph_tsvector, plainto_tsquery('english', 'Mario Kart')) AS text_score\n",
    "        FROM video_game_wikipedia\n",
    "        WHERE paragraph_tsvector @@ plainto_tsquery('english', 'Mario Kart')\n",
    "        ORDER BY text_score DESC\n",
    "        LIMIT 200\n",
    "    ),\n",
    "    combined AS (\n",
    "        SELECT f.id AS id, f.paragraph, f.text_score, v.vector_score,\n",
    "            0.7 * v.vector_score + 0.3 * f.text_score AS hybrid_score\n",
    "        FROM fts_query f\n",
    "        FULL OUTER JOIN vector_query v ON f.id = v.id\n",
    "    )\n",
    "    SELECT id, paragraph, hybrid_score\n",
    "    FROM combined\n",
    "    ORDER BY hybrid_score DESC\n",
    "    LIMIT 5;\n",
    "    '''\n",
    "\n",
    "    with psycopg2.connect(dbname=dbname, user=user, host=host) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query, (query_vector,))\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pgvector: Running the Concurrent Queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_id = '2251799813701581'\n",
    "query_vector = fetch_vector_pg(vector_id)\n",
    "\n",
    "\n",
    "num_concurrent_queries = 250\n",
    "start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent_queries) as executor:\n",
    "    # Fire off the same search query concurrently\n",
    "    futures = [executor.submit(execute_pgvector_search, query_vector) for _ in range(num_concurrent_queries)]\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Executed {num_concurrent_queries} concurrent queries.\")\n",
    "print(f\"Total execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "failed_count = sum(1 for f in futures if f.exception() is not None)\n",
    "print(f\"Failed queries: {failed_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SingleStore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch the vector\n",
    "def fetch_vector_s2(vector_id):\n",
    "    try:\n",
    "        conn = s2.connect(\n",
    "            host=s2_host,\n",
    "            port=port,\n",
    "            user=username,\n",
    "            password=password,\n",
    "            database=database,\n",
    "            autocommit=True\n",
    "        )\n",
    "        query = \"SELECT v FROM vecs_clean WHERE id = %s\"\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query, (vector_id,))\n",
    "            result = cursor.fetchone()\n",
    "        conn.close()\n",
    "        if result:\n",
    "            return json.dumps(result[0])\n",
    "        else:\n",
    "            print(\"Vector not found.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching vector: {e}\")\n",
    "        return None\n",
    "\n",
    "# Modify this function to use the extracted vector\n",
    "def execute_singlestore_search(vector):\n",
    "    query = f'''\n",
    "    with fts as(\n",
    "        select id, paragraph, match (paragraph) against ('AAA games') as score\n",
    "        from vecs_clean\n",
    "        where match (paragraph) against ('AAA games')\n",
    "        order by score desc\n",
    "        limit 200\n",
    "    ),\n",
    "    vs as (\n",
    "        select id, paragraph, v <*> {vector} as score\n",
    "        from vecs_clean\n",
    "        order by score use index (auto) desc\n",
    "        limit 200\n",
    "    )\n",
    "    select vs.id,\n",
    "        vs.paragraph,\n",
    "        .3 * ifnull(fts.score, 0) + .7 * vs.score as hybrid_score,\n",
    "        vs.score as vec_score,\n",
    "        ifnull(fts.score, 0) as ft_score\n",
    "    from fts full outer join vs\n",
    "        on fts.id = vs.id\n",
    "    order by hybrid_score desc\n",
    "    limit 5;\n",
    "    '''\n",
    "    # Add your existing database connection and query execution logic here\n",
    "    try:\n",
    "        # Establish a new connection for each query\n",
    "        conn = s2.connect(\n",
    "            host=s2_host,\n",
    "            port=port,\n",
    "            user=username,\n",
    "            password=password,\n",
    "            database=database,\n",
    "            autocommit=True\n",
    "        )        \n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query)\n",
    "            results = cursor.fetchall()\n",
    "        conn.close()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SingleStore: Running the Concurrent Queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_id = '2251799813701581'\n",
    "query_vector = fetch_vector_s2(vector_id)\n",
    "\n",
    "\n",
    "num_concurrent_queries = 250\n",
    "start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent_queries) as executor:\n",
    "    # Fire off the same search query concurrently\n",
    "    futures = [executor.submit(execute_singlestore_search, query_vector) for _ in range(num_concurrent_queries)]\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Executed {num_concurrent_queries} concurrent queries.\")\n",
    "print(f\"Total execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "failed_count = sum(1 for f in futures if f.exception() is not None)\n",
    "print(f\"Failed queries: {failed_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
